{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to model files\n",
    "import os\n",
    "MODELS_DIR = 'models\\\\'\n",
    "if not os.path.exists(MODELS_DIR):\n",
    "    os.mkdir(MODELS_DIR)\n",
    "MODEL_TF = MODELS_DIR + 'model'\n",
    "MODEL_NO_QUANT_TFLITE = MODELS_DIR + 'model_no_quant.tflite'\n",
    "MODEL_TFLITE = MODELS_DIR + 'model.tflite'\n",
    "MODEL_TFLITE_MICRO = MODELS_DIR + 'model.cc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cv2 import imwrite,imread\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "# Normalize the data\n",
    "train_images = train_images.astype(np.float32) / 255\n",
    "test_images = test_images.astype(np.float32) / 255\n",
    "# de 0 a 1 na escala 255 ou 8 bits\n",
    "train_images = np.expand_dims(train_images, -1)\n",
    "test_images = np.expand_dims(test_images, -1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> SAVE IMAGES IN DISK, FOR INFERENCE <p/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images2, train_labels2), (test_images2, test_labels2) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images2[2321].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images_rand(count): #escolhe aleatóriamente\n",
    "    rands = np.random.choice(10000,count)\n",
    "    # im = []\n",
    "    # for item in rands:\n",
    "    #     im.append(test_images2[item])\n",
    "\n",
    "    for i in rands:\n",
    "        path = f\"./saved/img/im_28x28_{i}.png\"\n",
    "        imwrite(path,test_images2[i])\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> formato da imagem salva<p/>\n",
    "<p> importante notar que se os dados devem ser pré-processados, para então ser preditos pela NN<p/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 3)\n",
      "(28, 28)\n",
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path = \"./saved/img/im_28x28_140.png\"\n",
    "im = imread(path)\n",
    "im = im.astype(np.float32) / 255\n",
    "print(im.shape)\n",
    "nw_img = im[:,:,1]\n",
    "print(nw_img.shape)\n",
    "nw_img = np.expand_dims(nw_img, -1)\n",
    "print(nw_img.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.1764706\n",
      "0.61960787\n",
      "0.5137255\n",
      "0.49803922\n",
      "0.5176471\n",
      "0.5254902\n",
      "0.5137255\n",
      "0.6431373\n",
      "0.07450981\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.36862746\n",
      "1.0\n",
      "0.81960785\n",
      "0.84313726\n",
      "0.87058824\n",
      "0.9137255\n",
      "0.88235295\n",
      "1.0\n",
      "0.3254902\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5294118\n",
      "0.8352941\n",
      "0.6901961\n",
      "0.69803923\n",
      "0.7176471\n",
      "0.7490196\n",
      "0.70980394\n",
      "0.8235294\n",
      "0.73333335\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.8235294\n",
      "0.78431374\n",
      "0.74509805\n",
      "0.7647059\n",
      "0.7764706\n",
      "0.80784315\n",
      "0.8235294\n",
      "0.79607844\n",
      "0.9882353\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.019607844\n",
      "0.9137255\n",
      "0.7372549\n",
      "0.7254902\n",
      "0.73333335\n",
      "0.7764706\n",
      "0.80784315\n",
      "0.84313726\n",
      "0.6862745\n",
      "1.0\n",
      "0.19215687\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.19607843\n",
      "0.9372549\n",
      "0.7372549\n",
      "0.7294118\n",
      "0.7176471\n",
      "0.7882353\n",
      "0.8392157\n",
      "0.8352941\n",
      "0.67058825\n",
      "1.0\n",
      "0.4\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.36862746\n",
      "0.9411765\n",
      "0.78431374\n",
      "0.77254903\n",
      "0.78039217\n",
      "0.8\n",
      "0.8039216\n",
      "0.7607843\n",
      "0.7058824\n",
      "0.9843137\n",
      "0.5411765\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.50980395\n",
      "0.9019608\n",
      "0.7411765\n",
      "0.7411765\n",
      "0.7529412\n",
      "0.8156863\n",
      "0.7529412\n",
      "0.7647059\n",
      "0.7294118\n",
      "0.98039216\n",
      "0.6156863\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.57254905\n",
      "0.8627451\n",
      "0.70980394\n",
      "0.7882353\n",
      "0.92156863\n",
      "0.8980392\n",
      "0.8\n",
      "0.83137256\n",
      "0.76862746\n",
      "0.99607843\n",
      "0.6117647\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5294118\n",
      "0.8666667\n",
      "0.78039217\n",
      "0.8784314\n",
      "0.90588236\n",
      "0.98039216\n",
      "0.76862746\n",
      "0.7882353\n",
      "0.7647059\n",
      "1.0\n",
      "0.5294118\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.4862745\n",
      "0.8980392\n",
      "0.76862746\n",
      "0.8627451\n",
      "1.0\n",
      "0.84313726\n",
      "0.85490197\n",
      "0.81960785\n",
      "0.78039217\n",
      "1.0\n",
      "0.4862745\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.45490196\n",
      "0.91764706\n",
      "0.8\n",
      "0.91764706\n",
      "1.0\n",
      "0.33333334\n",
      "0.89411765\n",
      "0.7921569\n",
      "0.80784315\n",
      "1.0\n",
      "0.45490196\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.37254903\n",
      "0.93333334\n",
      "0.79607844\n",
      "0.92941177\n",
      "1.0\n",
      "0.0\n",
      "0.9019608\n",
      "0.8117647\n",
      "0.81960785\n",
      "1.0\n",
      "0.39607844\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.3254902\n",
      "0.9607843\n",
      "0.79607844\n",
      "0.96862745\n",
      "0.9882353\n",
      "0.0\n",
      "0.87058824\n",
      "0.84705883\n",
      "0.8039216\n",
      "1.0\n",
      "0.38431373\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.2784314\n",
      "0.99607843\n",
      "0.83137256\n",
      "0.9882353\n",
      "0.9607843\n",
      "0.0\n",
      "0.7647059\n",
      "0.91764706\n",
      "0.79607844\n",
      "1.0\n",
      "0.39215687\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.25490198\n",
      "0.99607843\n",
      "0.83137256\n",
      "0.9411765\n",
      "0.8745098\n",
      "0.0\n",
      "0.6392157\n",
      "0.98039216\n",
      "0.8039216\n",
      "1.0\n",
      "0.39607844\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.20784314\n",
      "0.99607843\n",
      "0.8352941\n",
      "0.95686275\n",
      "0.74509805\n",
      "0.0\n",
      "0.5294118\n",
      "0.99607843\n",
      "0.8\n",
      "1.0\n",
      "0.33333334\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.14901961\n",
      "0.99607843\n",
      "0.8392157\n",
      "0.9764706\n",
      "0.64705884\n",
      "0.0\n",
      "0.41960785\n",
      "0.99607843\n",
      "0.8\n",
      "1.0\n",
      "0.22745098\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.047058824\n",
      "0.99607843\n",
      "0.8509804\n",
      "0.99607843\n",
      "0.5921569\n",
      "0.0\n",
      "0.37254903\n",
      "1.0\n",
      "0.8\n",
      "1.0\n",
      "0.12156863\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.9882353\n",
      "0.8745098\n",
      "0.99607843\n",
      "0.4862745\n",
      "0.0\n",
      "0.27058825\n",
      "1.0\n",
      "0.8156863\n",
      "1.0\n",
      "0.019607844\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.9764706\n",
      "0.89411765\n",
      "0.972549\n",
      "0.3137255\n",
      "0.0\n",
      "0.08235294\n",
      "1.0\n",
      "0.8352941\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.9411765\n",
      "0.9137255\n",
      "0.9490196\n",
      "0.19607843\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.8392157\n",
      "1.0\n",
      "0.003921569\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.8901961\n",
      "0.92156863\n",
      "0.9411765\n",
      "0.13725491\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.827451\n",
      "1.0\n",
      "0.023529412\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.84313726\n",
      "0.9372549\n",
      "0.93333334\n",
      "0.07058824\n",
      "0.0\n",
      "0.0\n",
      "0.9882353\n",
      "0.8352941\n",
      "1.0\n",
      "0.09411765\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.8156863\n",
      "0.9490196\n",
      "0.92156863\n",
      "0.039215688\n",
      "0.0\n",
      "0.0\n",
      "0.99607843\n",
      "0.81960785\n",
      "0.8784314\n",
      "0.11764706\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.6862745\n",
      "0.93333334\n",
      "0.90588236\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.8156863\n",
      "0.8039216\n",
      "0.8862745\n",
      "0.14901961\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.8509804\n",
      "1.0\n",
      "0.90588236\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.8784314\n",
      "0.9490196\n",
      "0.32156864\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.2509804\n",
      "0.5647059\n",
      "0.14901961\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.18431373\n",
      "0.46666667\n",
      "0.6156863\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(28):\n",
    "    for j in range(28):\n",
    "        print(nw_img[i,j,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 6)         60        \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 6)         330       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3456)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                34570     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,960\n",
      "Trainable params: 34,960\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "input_shape = (28, 28, 1)\n",
    "num_classes = 10\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(6, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.Conv2D(6, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"), # RESULTADO SÃO 10 TIPOS DE ROUPA\n",
    "    ]\n",
    ")\n",
    "model.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "canal da imagem de saída corresponde a um neurônio da camada?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nikolaos\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\backend.py:5582: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.4791 - accuracy: 0.8301 - val_loss: 0.3903 - val_accuracy: 0.8558\n",
      "Epoch 2/20\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.3509 - accuracy: 0.8746 - val_loss: 0.3491 - val_accuracy: 0.8763\n",
      "Epoch 3/20\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.3181 - accuracy: 0.8851 - val_loss: 0.3360 - val_accuracy: 0.8784\n",
      "Epoch 4/20\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.2885 - accuracy: 0.8951 - val_loss: 0.3101 - val_accuracy: 0.8897\n",
      "Epoch 5/20\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.2674 - accuracy: 0.9020 - val_loss: 0.3170 - val_accuracy: 0.8886\n",
      "Epoch 6/20\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.2502 - accuracy: 0.9082 - val_loss: 0.3056 - val_accuracy: 0.8956\n",
      "Epoch 7/20\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.2351 - accuracy: 0.9149 - val_loss: 0.3040 - val_accuracy: 0.8978\n",
      "Epoch 8/20\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.2214 - accuracy: 0.9197 - val_loss: 0.3035 - val_accuracy: 0.8969\n",
      "Epoch 9/20\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.2091 - accuracy: 0.9240 - val_loss: 0.2954 - val_accuracy: 0.9010\n",
      "Epoch 10/20\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1980 - accuracy: 0.9272 - val_loss: 0.3059 - val_accuracy: 0.8979\n",
      "Epoch 11/20\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1885 - accuracy: 0.9324 - val_loss: 0.3226 - val_accuracy: 0.8947\n",
      "Epoch 12/20\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1806 - accuracy: 0.9345 - val_loss: 0.3136 - val_accuracy: 0.8964\n",
      "Epoch 13/20\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1722 - accuracy: 0.9373 - val_loss: 0.3220 - val_accuracy: 0.8948\n",
      "Epoch 14/20\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1649 - accuracy: 0.9394 - val_loss: 0.3392 - val_accuracy: 0.8936\n",
      "Epoch 15/20\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1591 - accuracy: 0.9417 - val_loss: 0.3366 - val_accuracy: 0.8978\n",
      "Epoch 16/20\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1533 - accuracy: 0.9458 - val_loss: 0.3513 - val_accuracy: 0.8942\n",
      "Epoch 17/20\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1485 - accuracy: 0.9452 - val_loss: 0.3491 - val_accuracy: 0.8977\n",
      "Epoch 18/20\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1428 - accuracy: 0.9475 - val_loss: 0.3665 - val_accuracy: 0.8921\n",
      "Epoch 19/20\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1380 - accuracy: 0.9486 - val_loss: 0.3598 - val_accuracy: 0.8945\n",
      "Epoch 20/20\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1330 - accuracy: 0.9518 - val_loss: 0.3637 - val_accuracy: 0.8966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1da332a5a80>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>salve o modelo<p/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save the model to disk\n",
    "model.save(MODEL_TF)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> teste a acurácia<p/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 34/313 [==>...........................] - ETA: 0s - loss: 0.3446 - accuracy: 0.8952"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nikolaos\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\backend.py:5582: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3938 - accuracy: 0.8886\n",
      "\n",
      "Test accuracy: 0.8885999917984009\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.7340051e-11, 4.3830321e-19, 1.8910325e-11, 5.3509796e-12,\n",
       "       3.2970025e-15, 8.4616302e-05, 1.2833290e-12, 1.6768759e-05,\n",
       "       1.6661293e-08, 9.9989855e-01], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(test_images)\n",
    "predictions[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predição de valores\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantizar o modelo tf_lite"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No quantized model is 142428 bytes\n"
     ]
    }
   ],
   "source": [
    "# Convert the model to the TensorFlow Lite format without quantization\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_TF)\n",
    "model_no_quant_tflite = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "size = open(MODEL_NO_QUANT_TFLITE, \"wb\").write(model_no_quant_tflite)\n",
    "print(\"No quantized model is %d bytes\" % size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized model is 38616 bytes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert the model to the TensorFlow Lite format with quantization\n",
    "def representative_dataset():\n",
    " for input_value in tf.data.Dataset.from_tensor_slices(train_images).batch(1).take(100):\n",
    "    yield [input_value]\n",
    "# Set the optimization flag.\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Provide a representative dataset to ensure we quantize correctly.\n",
    "converter.representative_dataset = representative_dataset\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "tflite_model_size = open(MODEL_TFLITE, \"wb\").write(tflite_model)\n",
    "print(\"Quantized model is %d bytes\" % tflite_model_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'sed' n�o � reconhecido como um comando interno\n",
      "ou externo, um programa oper�vel ou um arquivo em lotes.\n"
     ]
    }
   ],
   "source": [
    "# Install xxd if it is not available\n",
    "\n",
    "# Convert to a C source file, i.e, a TensorFlow Lite for Microcontrollers model\n",
    "!xxd -i {MODEL_TFLITE} > {MODEL_TFLITE_MICRO}\n",
    "# Update variable names\n",
    "REPLACE_TEXT = MODEL_TFLITE.replace('/', '_').replace('.', '_')\n",
    "!sed -i 's/'{REPLACE_TEXT}'/g_model/g' {MODEL_TFLITE_MICRO}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "teste --ABAIXO--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(test_images.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c799f6556e690be50cab7b0017f988fc83eedda4430b8ab5ab7fc6e1038060c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
